{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:17:14.893599Z",
     "start_time": "2025-02-02T15:16:38.627905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from dao.attribute import DAOAttributePL\n",
    "from models.attribute import AttributePLInDB\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "dao_attribute: DAOAttributePL = DAOAttributePL(collection_name=\"attributes-24-12-16-recalc-24-12-22.1-pgryka\")\n",
    "\n",
    "attributes_generated: List[AttributePLInDB] = dao_attribute.find_many_by_query({\"is_generated\": True})\n",
    "attributes_real: List[AttributePLInDB] = dao_attribute.find_many_by_query({\"is_generated\": False})\n",
    "\n",
    "dicts_generated = [{\"text\": attribute.stylometrix_metrics.text, \"label\": 1} for attribute in attributes_generated]\n",
    "dicts_real = [{\"text\": attribute.stylometrix_metrics.text, \"label\": 0} for attribute in attributes_real]\n",
    "combined = dicts_generated + dicts_real\n",
    "dataset_whole = Dataset.from_list(combined)"
   ],
   "id": "b7c22214e31c254a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:45:49.874895Z",
     "start_time": "2025-02-02T15:45:49.863701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "split_dataset = dataset_whole.train_test_split(test_size=0.3)\n",
    "\n",
    "# Extract the train and test subsets\n",
    "train_dataset_before_tokenizer = split_dataset[\"train\"]\n",
    "test_dataset_before_tokenizer = split_dataset[\"test\"]"
   ],
   "id": "717e7e587d95ec07",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T15:44:21.341467Z",
     "start_time": "2025-02-02T15:20:19.028307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = \"sdadas/polish-roberta-large-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name, num_labels=2)"
   ],
   "id": "fc94b6854e3c4946",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/344 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "189e7423aa1f4f24b9860cffa28ab693"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/8.59M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8014ce66eaca4abd8b920a65e88db262"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c80c14e6cf8841318294dba5c60d49fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d82b4f6683a44ae0a244fe0048a1beca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.74G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6595486a234349e48f1b2037e37a52e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T16:13:50.371041Z",
     "start_time": "2025-02-02T16:13:15.385978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(example):\n",
    "    encoding = tokenizer(\n",
    "        example['text'],\n",
    "        max_length=512,\n",
    "        truncation=True,\n",
    "        stride=256,\n",
    "        return_overflowing_tokens=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    n_chunks = encoding[\"input_ids\"].shape[0]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": [encoding[\"input_ids\"][i].tolist() for i in range(n_chunks)],\n",
    "        \"attention_mask\": [encoding[\"attention_mask\"][i].tolist() for i in range(n_chunks)],\n",
    "        \"label\": [example[\"label\"]] * n_chunks\n",
    "    }\n",
    "def tokenize_function_batch(batch):\n",
    "    \"\"\"\n",
    "    Processes a batch of examples and tokenizes each text using a sliding window.\n",
    "    Each long text may produce several chunks; this function flattens them so that\n",
    "    every chunk becomes a separate example with its own scalar label.\n",
    "\n",
    "    Args:\n",
    "        batch (dict): A dictionary with keys \"text\" and \"label\", where each value is a list.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys \"input_ids\", \"attention_mask\", and \"label\",\n",
    "              where each value is a list of length equal to the total number of chunks produced.\n",
    "    \"\"\"\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Loop over each example in the batch.\n",
    "    for text, label in zip(batch[\"text\"], batch[\"label\"]):\n",
    "        # Use the built-in sliding window functionality.\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            stride=256,\n",
    "            return_overflowing_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        # Number of chunks produced for this text.\n",
    "        num_chunks = encoding[\"input_ids\"].shape[0]\n",
    "        # For each chunk, add its token ids, attention mask, and the same scalar label.\n",
    "        for i in range(num_chunks):\n",
    "            all_input_ids.append(encoding[\"input_ids\"][i].tolist())\n",
    "            all_attention_masks.append(encoding[\"attention_mask\"][i].tolist())\n",
    "            all_labels.append(label)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": all_input_ids,\n",
    "        \"attention_mask\": all_attention_masks,\n",
    "        \"label\": all_labels\n",
    "    }\n",
    "\n",
    "train_dataset = train_dataset_before_tokenizer.map(tokenize_function_batch, batched=True, remove_columns=[\"text\"])\n",
    "test_dataset = test_dataset_before_tokenizer.map(tokenize_function_batch, batched=True, remove_columns=[\"text\"])"
   ],
   "id": "d6109c17ac62555b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/3329 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ceb2f491d40347099b22520a24d906fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1427 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24582f17ca2b44d883e5bd1771c30fa7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T16:15:16.911758Z",
     "start_time": "2025-02-02T16:15:16.904811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = train_dataset.with_format(\"torch\")\n",
    "test_dataset = test_dataset.with_format(\"torch\")\n"
   ],
   "id": "2e5f0c6a5ef4556a",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T16:21:16.428486Z",
     "start_time": "2025-02-02T16:21:16.408499Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "execution_count": 26,
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,  # MLM stands for masked language modeling\n",
    "    mlm_probability=0.15\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute accuracy or other metrics after each evaluation.\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=-1)\n",
    "    accuracy = (predictions == labels).float().mean()\n",
    "    return {\"accuracy\": accuracy.item()}\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Rename 'label' to 'labels' if present\n",
    "        if 'label' in inputs:\n",
    "            inputs['labels'] = inputs.pop('label')\n",
    "        return super().compute_loss(model, inputs, return_outputs=return_outputs)\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ],
   "id": "f1a9891fe29f5be5"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-02-02T16:21:17.817503Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "d2384b07573da080",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 13927\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5223\n",
      "  Number of trainable parameters = 435091457\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "results = trainer.evaluate(test_dataset)\n",
    "print(results)"
   ],
   "id": "b8a1bd5a28b503d8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T17:15:20.666388Z",
     "start_time": "2025-01-25T17:15:18.425735Z"
    }
   },
   "cell_type": "code",
   "source": "from transformers_interpret import SequenceClassificationExplainer",
   "id": "c155e1c8bde1329a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the tokenizer and model you just fine-tuned\n",
    "# If you've saved locally, pass the local path of your checkpoint\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./results\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"./results\")\n",
    "\n",
    "# Create the explainer\n",
    "cls_explainer = SequenceClassificationExplainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "text = \"To jest przykładowe zdanie do sprawdzenia.\"\n",
    "\n",
    "# Get word attributions\n",
    "word_attributions = cls_explainer(text)\n",
    "\n",
    "# word_attributions is a list of tuples: [(token_1, attribution_score_1), (token_2, ...), ...]\n",
    "print(word_attributions)\n"
   ],
   "id": "e905b81e528fd07b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
